{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMufG/h5WXK3FmxfDKOELYe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndromedaOMA/Advanced_Chapters_of_Neural_Network---Laboratories/blob/main/NoisyCIFAR100_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the environment requirements\n"
      ],
      "metadata": {
        "id": "T3B8ehtlqO2y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount drive"
      ],
      "metadata": {
        "id": "fhaqg9UuqUyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgx9v2VMk0SV",
        "outputId": "b2665450-2f0c-43ba-9222-323c3ff2d4e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install pip packages\n"
      ],
      "metadata": {
        "id": "T62Y_SQMqYd3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Je4xuhbjalU6"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "import subprocess\n",
        "\n",
        "root_path = \"/content/drive/MyDrive/NoisyCIFAR100\"\n",
        "\n",
        "with open(f\"{root_path}/environment.yaml\") as f:\n",
        "    env = yaml.safe_load(f)\n",
        "\n",
        "# Collect pip packages\n",
        "pip_packages = []\n",
        "for dep in env.get(\"dependencies\", []):\n",
        "    if isinstance(dep, dict) and \"pip\" in dep:\n",
        "        pip_packages.extend(dep[\"pip\"])\n",
        "\n",
        "# Install all pip packages at once\n",
        "if pip_packages:\n",
        "    subprocess.run([\"pip\", \"install\", *pip_packages])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install detectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "52CB9oiws0cu",
        "outputId": "30838f39-1c5e-435e-b315-f3784b5c120a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting detectors\n",
            "  Using cached detectors-0.1.11-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from detectors) (11.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from detectors) (2.0.2)\n",
            "Collecting optuna (from detectors)\n",
            "  Using cached optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from detectors) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from detectors) (0.25.2)\n",
            "Requirement already satisfied: timm>=0.8.19.dev0 in /usr/local/lib/python3.12/dist-packages (from detectors) (1.0.22)\n",
            "Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.12/dist-packages (from detectors) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from detectors) (0.24.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from detectors) (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from detectors) (1.16.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (from detectors) (1.12.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from detectors) (5.9.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from detectors) (2.2.2)\n",
            "Collecting wilds (from detectors)\n",
            "  Downloading wilds-2.0.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting faiss-cpu (from detectors)\n",
            "  Using cached faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from detectors) (3.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm>=0.8.19.dev0->detectors) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm>=0.8.19.dev0->detectors) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm>=0.8.19.dev0->detectors) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->detectors) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->detectors) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->detectors) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->detectors) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->detectors) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->detectors) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->detectors) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->detectors) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->detectors) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->detectors) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->detectors) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->detectors) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->detectors) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->detectors) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->detectors) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->detectors) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->detectors) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->detectors) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->detectors) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->detectors) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->detectors) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->detectors) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.1->detectors) (3.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate->detectors) (25.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectors) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectors) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectors) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectors) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectors) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->detectors) (2.9.0.post0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna->detectors) (1.17.2)\n",
            "Collecting colorlog (from optuna->detectors)\n",
            "  Using cached colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna->detectors) (2.0.44)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->detectors) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->detectors) (2025.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->detectors) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->detectors) (2025.10.16)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->detectors) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->detectors) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->detectors) (3.6.0)\n",
            "Collecting ogb>=1.2.6 (from wilds->detectors)\n",
            "  Using cached ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting outdated>=0.2.0 (from wilds->detectors)\n",
            "  Using cached outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna->detectors) (1.3.10)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm>=0.8.19.dev0->detectors) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm>=0.8.19.dev0->detectors) (1.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from ogb>=1.2.6->wilds->detectors) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from ogb>=1.2.6->wilds->detectors) (2.5.0)\n",
            "Collecting littleutils (from outdated>=0.2.0->wilds->detectors)\n",
            "  Using cached littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna->detectors) (3.2.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.1->detectors) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.1->detectors) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm>=0.8.19.dev0->detectors) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm>=0.8.19.dev0->detectors) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm>=0.8.19.dev0->detectors) (2025.11.12)\n",
            "Downloading detectors-0.1.11-py3-none-any.whl (616 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.8/616.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wilds-2.0.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.2/126.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Downloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Installing collected packages: littleutils, faiss-cpu, colorlog, outdated, optuna, ogb, wilds, detectors\n",
            "Successfully installed colorlog-6.10.1 detectors-0.1.11 faiss-cpu-1.13.0 littleutils-0.2.4 ogb-1.3.6 optuna-4.6.0 outdated-0.2.2 wilds-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verify the installation\n"
      ],
      "metadata": {
        "id": "Vx-b0aZoqgyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show detectors"
      ],
      "metadata": {
        "id": "RLBNdyD5ar5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "0846e6a8-7ad4-473a-fc80-c28e82939058"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: detectors\n",
            "Version: 0.1.11\n",
            "Summary: Detectors: a python package to benchmark generalized out-of-distribution detection methods.\n",
            "Home-page: https://github.com/edadaltocg/detectors\n",
            "Author: Eduardo Dadalto\n",
            "Author-email: edadaltocg@gmail.com\n",
            "License: APACHE 2.0\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: accelerate, faiss-cpu, matplotlib, numpy, optuna, pandas, Pillow, psutil, scikit-image, scikit-learn, scipy, timm, torch, torchvision, tqdm, wilds\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import"
      ],
      "metadata": {
        "id": "yK8jZS5qvaCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "import timm\n",
        "import sys\n",
        "import detectors\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "# from sam import SAM\n",
        "\n",
        "import yaml\n",
        "\n",
        "import torch"
      ],
      "metadata": {
        "id": "fQe8ZnwhsexU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing the data"
      ],
      "metadata": {
        "id": "78gOUgKLq0Vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(config):\n",
        "    if config['dataset']['name'] == 'MNIST':\n",
        "        train_transformer = transforms.Compose([\n",
        "            transforms.RandomAffine(degrees=2, translate=[0.1, 0.1]),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
        "        ])\n",
        "        test_transformer = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
        "        ])\n",
        "        train_dataset = datasets.MNIST(root=f'{config[\"dataset\"][\"data_dir\"]}/train', train=True, transform=train_transformer, download=True)\n",
        "        test_dataset = datasets.MNIST(root=f'{config[\"dataset\"][\"data_dir\"]}/test', train=False, transform=test_transformer, download=True)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=config['dataset']['batch_size'], shuffle=True, pin_memory=True)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=config['dataset']['batch_size'], shuffle=False, pin_memory=True)\n",
        "        return train_loader, test_loader\n",
        "\n",
        "    elif config['dataset']['name'] == 'CIFAR10':\n",
        "        mean = list(map(float, config[\"dataset\"][\"mean\"]))\n",
        "        std = list(map(float, config[\"dataset\"][\"std\"]))\n",
        "\n",
        "        train_transformer = transforms.Compose([\n",
        "            # transforms.ToPILImage(),\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(15),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ])\n",
        "        test_transformer = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ])\n",
        "\n",
        "        train_dataset = datasets.CIFAR10(root=f'{config[\"dataset\"][\"data_dir\"]}/train', train=True, transform=train_transformer, download=True)\n",
        "        test_dataset = datasets.CIFAR10(root=f'{config[\"dataset\"][\"data_dir\"]}/test', train=False, transform=test_transformer, download=True)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=config['dataset']['batch_size'], shuffle=True, pin_memory=True)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=config['dataset']['batch_size'], shuffle=False, pin_memory=True)\n",
        "        return train_loader, test_loader\n",
        "\n",
        "    elif config['dataset']['name'] == 'CIFAR100':\n",
        "        mean = list(map(float, config[\"dataset\"][\"mean\"]))\n",
        "        std = list(map(float, config[\"dataset\"][\"std\"]))\n",
        "\n",
        "        train_transformer = transforms.Compose([\n",
        "            # transforms.ToPILImage(),\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(15),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ])\n",
        "        test_transformer = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ])\n",
        "\n",
        "        train_dataset = datasets.CIFAR100(root=f'{config[\"dataset\"][\"data_dir\"]}/train', train=True, transform=train_transformer, download=True)\n",
        "        test_dataset = datasets.CIFAR100(root=f'{config[\"dataset\"][\"data_dir\"]}/test', train=False, transform=test_transformer, download=True)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=config['dataset']['batch_size'], shuffle=True, pin_memory=True)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=config['dataset']['batch_size'], shuffle=False, pin_memory=True)\n",
        "        return train_loader, test_loader\n",
        "\n",
        "    elif config['dataset']['name'] == 'OxfordIIITPet':\n",
        "        mean = list(map(float, config[\"dataset\"][\"mean\"]))\n",
        "        std = list(map(float, config[\"dataset\"][\"std\"]))\n",
        "\n",
        "        train_transformer = transforms.Compose([\n",
        "            # transforms.ToPILImage(),\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(15),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ])\n",
        "        test_transformer = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ])\n",
        "\n",
        "        train_dataset = datasets.OxfordIIITPet(root=f'{config[\"dataset\"][\"data_dir\"]}/train', train=True, transform=train_transformer, download=True)\n",
        "        test_dataset = datasets.OxfordIIITPet(root=f'{config[\"dataset\"][\"data_dir\"]}/test', train=False, transform=test_transformer, download=True)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=config['dataset']['batch_size'], shuffle=True, pin_memory=True)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=config['dataset']['batch_size'], shuffle=False, pin_memory=True)\n",
        "        return train_loader, test_loader\n",
        "    else:\n",
        "        print('The dataset name you have entered is not supported!')\n",
        "        sys.exit()"
      ],
      "metadata": {
        "id": "038APgknq3G9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get the Loss Function"
      ],
      "metadata": {
        "id": "3SCKGd1Kq9-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_function(name):\n",
        "    name = name.lower()\n",
        "    if name == 'crossentropyloss':\n",
        "        print('CrossEntropyLoss Loss Function loaded!')\n",
        "        return torch.nn.CrossEntropyLoss()\n",
        "    elif name == 'mseloss':\n",
        "        print('MSELoss Loss Function loaded!')\n",
        "        return torch.nn.MSELoss()\n",
        "    else:\n",
        "        print('The loss function name you have entered is not supported!')\n",
        "        sys.exit()"
      ],
      "metadata": {
        "id": "SRHhWM4_rCLT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Learning Rate Scheduler"
      ],
      "metadata": {
        "id": "Cy0_7CC7rGxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lr_scheduler(configs, optimizer):\n",
        "    name = configs[\"training\"][\"scheduler\"].lower()\n",
        "    if name == 'steplr':\n",
        "        print('StepLR Learning Rate Scheduler loaded!')\n",
        "        return torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                               step_size=configs[\"training\"][\"step_size\"],\n",
        "                                               gamma=configs[\"training\"][\"gamma\"])\n",
        "    elif name == 'reducelronplateau':\n",
        "        print('ReduceLROnPlateau Learning Rate Scheduler loaded!')\n",
        "        return torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                          mode=configs[\"training\"][\"mode\"],\n",
        "                                                          factor=configs[\"training\"][\"factor\"],\n",
        "                                                          patience=configs[\"training\"][\"patience\"],\n",
        "                                                          threshold=configs[\"training\"][\"threshold\"])\n",
        "    else:\n",
        "        print('The Learning Rate Scheduler name you have entered is not supported!')\n",
        "        sys.exit()"
      ],
      "metadata": {
        "id": "-CsCyJ0lrJWL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get the model"
      ],
      "metadata": {
        "id": "RkDvgUvqrLfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(name, config):\n",
        "    name = name.lower()\n",
        "    if name == 'resnet50':\n",
        "        # model = timm.create_model(\"hf_hub:anonauthors/cifar100-timm-resnet50\", pretrained=config['model']['pretrained'])  # https://huggingface.co/anonauthors/cifar100-timm-resnet50\n",
        "        model = timm.create_model(\"resnet50_cifar100\", pretrained=True)     # https://huggingface.co/edadaltocg/resnet50_cifar100\n",
        "        print('Model resnet50_cifar100 loaded!')\n",
        "        return model\n",
        "    elif name == 'resnet18':\n",
        "        model = timm.create_model(\"resnet18_cifar100\", pretrained=config['model']['pretrained'])    # https://huggingface.co/edadaltocg/resnet18_cifar100\n",
        "        print('Model resnet18_cifar100 loaded!')\n",
        "        return model\n",
        "    elif name == 'resnest14d':\n",
        "        model = timm.create_model(\"hf_hub:timm/resnest14d.gluon_in1k\", pretrained=config['model']['pretrained'])\n",
        "        print('Model resnest14d.gluon_in1k loaded!')\n",
        "        return model\n",
        "    elif name == 'resnest26d':\n",
        "        model = timm.create_model(\"hf_hub:timm/resnest26d.gluon_in1k\", pretrained=config['model']['pretrained'])\n",
        "        print('Model resnest26d.gluon_in1k loaded!')\n",
        "        return model\n",
        "    elif name == 'MLP':\n",
        "        pass\n",
        "    else:\n",
        "        print('The network name you have entered is not supported!')\n",
        "        sys.exit()"
      ],
      "metadata": {
        "id": "04hSMOIzrNMy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get the optimizer"
      ],
      "metadata": {
        "id": "3CHXWt8XrPsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_optimizer(configs, params):\n",
        "    name = configs[\"training\"][\"optimizer\"].lower()\n",
        "    if name == 'sgd':\n",
        "        print('SGD Optimizer loaded!')\n",
        "        return torch.optim.SGD(params, lr=configs[\"training\"][\"learning_rate\"], momentum=configs[\"training\"][\"momentum\"], weight_decay=float(configs[\"training\"][\"weight_decay\"]))\n",
        "    elif name == 'adam':\n",
        "        print('Adam Optimizer loaded!')\n",
        "        return torch.optim.Adam(params, lr=configs[\"training\"][\"learning_rate\"])\n",
        "    elif name == 'adamw':\n",
        "        print('AdamW Optimizer loaded!')\n",
        "        return torch.optim.AdamW(params, lr=configs[\"training\"][\"learning_rate\"], weight_decay=float(configs[\"training\"][\"weight_decay\"]))\n",
        "    elif name == 'muon':\n",
        "        print('Muon Optimizer loaded!')\n",
        "        return torch.optim.Muon(params, lr=configs[\"training\"][\"learning_rate\"], weight_decay=float(configs[\"training\"][\"weight_decay\"]))\n",
        "    # elif name == 'sam':\n",
        "    #     print('Optimizer loaded!')\n",
        "    #     # base_optim = torch.optim.SGD(params, lr=configs[\"training\"][\"learning_rate\"], momentum=configs[\"training\"][\"momentum\"], weight_decay=float(configs[\"training\"][\"weight_decay\"]))\n",
        "    #     base_optim = torch.optim.SGD\n",
        "    #     return SAM(params, base_optim, lr=configs[\"training\"][\"learning_rate\"], momentum=float(configs[\"training\"][\"momentum\"]))\n",
        "    else:\n",
        "        print('The optimizer name you have entered is not supported!')\n",
        "        sys.exit()"
      ],
      "metadata": {
        "id": "rV7OrpKdrRmz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get YAML Configuration"
      ],
      "metadata": {
        "id": "K8vRrTJfrbfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_config(config_path):\n",
        "    with open(config_path) as f:\n",
        "        config = yaml.safe_load(f)\n",
        "    return config"
      ],
      "metadata": {
        "id": "8mDV9as8rfpl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Mixed Precision"
      ],
      "metadata": {
        "id": "wpqOikNBri0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mixed_precision():\n",
        "    return torch.amp.GradScaler()"
      ],
      "metadata": {
        "id": "p_Lyr3DhrmMV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "syqEN315qkfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "\n",
        "import pprint\n",
        "import wandb\n",
        "\n",
        "wandb.login()\n",
        "scaler = get_mixed_precision()\n",
        "\n",
        "\n",
        "def train_per_epoch(epoch):\n",
        "    global model, optimizer, loss_function, scheduler, writer, train_loader\n",
        "\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for batch_index, (train_images, train_labels) in enumerate(\n",
        "            tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
        "    ):\n",
        "        train_images, train_labels = train_images.to(device), train_labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.amp.autocast(device_type='cuda'):\n",
        "            outputs = model(train_images)\n",
        "            loss = loss_function(outputs, train_labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        n_iter = (epoch - 1) * len(train_loader) + batch_index + 1\n",
        "        writer.add_scalar(\"Train/Loss\", loss.item(), n_iter)\n",
        "\n",
        "        # W&B\n",
        "        wandb.log({\"train_loss\": loss.item()})\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    return train_loss / len(train_loader)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_training(epoch=0):\n",
        "    global model, loss_function, test_loader, writer\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "\n",
        "    for test_images, test_labels in test_loader:\n",
        "        test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
        "\n",
        "        outputs = model(test_images)\n",
        "        test_loss += loss_function(outputs, test_labels).item()\n",
        "\n",
        "        correct += (outputs.argmax(1) == test_labels).sum().item()\n",
        "\n",
        "    avg_loss = test_loss / len(test_loader)\n",
        "    accuracy = 100.0 * correct / len(test_loader.dataset)\n",
        "\n",
        "    print(f\"Epoch {epoch}: Test Loss {avg_loss:.3f}, Accuracy {accuracy:.3f}%\")\n",
        "\n",
        "    writer.add_scalar(\"Test/Loss\", avg_loss, epoch)\n",
        "    writer.add_scalar(\"Test/Accuracy\", accuracy, epoch)\n",
        "\n",
        "    wandb.log({\"val_loss\": avg_loss, \"val_acc\": accuracy})\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def sweep_train():\n",
        "    global model, train_loader, test_loader, writer, loss_function, optimizer, scheduler, device\n",
        "\n",
        "    run = wandb.init(project=\"NoisyCIFAR100\")\n",
        "    config_wb = wandb.config\n",
        "\n",
        "    device = config['experiment']['device']\n",
        "\n",
        "    experiment_number = config['experiment']['number']\n",
        "\n",
        "    # override with sweep hyperparameters\n",
        "    config['training']['learning_rate'] = config_wb.learning_rate\n",
        "    config['training']['weight_decay'] = config_wb.weight_decay\n",
        "    config['dataset']['batch_size'] = config_wb.batch_size\n",
        "    config['training']['optimizer'] = config_wb.optimizer\n",
        "\n",
        "    train_loader, test_loader = preprocessing(config)\n",
        "    model = get_model(config['model']['name'], config).to(device)\n",
        "    loss_function = get_loss_function(config[\"training\"][\"loss_function\"])\n",
        "    optimizer = get_optimizer(config, model.parameters())\n",
        "    scheduler = get_lr_scheduler(config, optimizer)\n",
        "\n",
        "    log_dir = f'../experiments/experiment{experiment_number}/results'\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "    writer = SummaryWriter(\n",
        "        os.path.join(log_dir, datetime.now().strftime(config[\"experiment\"][\"date_format\"]))\n",
        "    )\n",
        "\n",
        "    best_acc = 0\n",
        "    for epoch in range(1, config['training']['epochs'] + 1):\n",
        "        train_per_epoch(epoch)\n",
        "        acc = eval_training(epoch)\n",
        "\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            checkpoint_dir = f'../experiments/experiment{experiment_number}/checkpoints'\n",
        "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "            torch.save(model.state_dict(), os.path.join(\n",
        "                checkpoint_dir, f'best_model_{best_acc}.pth'\n",
        "            ))\n",
        "\n",
        "    writer.close()\n",
        "    run.finish()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(\"Type the number of the experiment you want to run:\")\n",
        "    experiment_number = int(input())\n",
        "    config = load_config(f\"{root_path}/experiment{experiment_number}/config.yml\")\n",
        "\n",
        "    pprint.pprint(f\"Sweep configuration: {config['sweep']}\")\n",
        "\n",
        "    sweep_id = wandb.sweep(config['sweep'], project=\"NoisyCIFAR100\")\n",
        "    wandb.agent(sweep_id, function=sweep_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iUXUij9PoxBr",
        "outputId": "3fed654e-3143-48de-9b12-0a9fb6df6325"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmarius-alexandru-olaru\u001b[0m (\u001b[33mmarius-alexandru-olaru-fii-uaic\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type the number of the experiment you want to run:\n",
            "1\n",
            "(\"Sweep configuration: {'method': 'bayes', 'metric': {'name': 'val_acc', \"\n",
            " \"'goal': 'maximize'}, 'parameters': {'learning_rate': {'distribution': \"\n",
            " \"'uniform', 'min': '1e-4', 'max': '3e-3'}, 'batch_size': {'values': [32, 64, \"\n",
            " \"128]}, 'weight_decay': {'distribution': 'uniform', 'min': 0.0, 'max': \"\n",
            " \"0.005}, 'optimizer': {'values': ['SGD', 'Adam', 'AdamW']}}}\")\n",
            "Create sweep with ID: 8lfbxp0y\n",
            "Sweep URL: https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/sweeps/8lfbxp0y\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: et4y8sbl with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0008017152659061111\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: AdamW\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0038541705822874145\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'NoisyCIFAR100' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251204_151546-et4y8sbl</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/runs/et4y8sbl' target=\"_blank\">glamorous-sweep-1</a></strong> to <a href='https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/sweeps/8lfbxp0y' target=\"_blank\">https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/sweeps/8lfbxp0y</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100' target=\"_blank\">https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/sweeps/8lfbxp0y' target=\"_blank\">https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/sweeps/8lfbxp0y</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/runs/et4y8sbl' target=\"_blank\">https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/runs/et4y8sbl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:05<00:00, 30.9MB/s]\n",
            "100%|██████████| 169M/169M [00:04<00:00, 35.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://huggingface.co/edadaltocg/resnet50_cifar100/resolve/main/pytorch_model.bin\" to /root/.cache/torch/hub/checkpoints/resnet50_cifar100.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/wandb/agents/pyagent.py\", line 297, in _run_job\n",
            "    self._function()\n",
            "  File \"/tmp/ipython-input-941492003.py\", line 94, in sweep_train\n",
            "    model = get_model(config['model']['name'], config).to(device)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3748646692.py\", line 5, in get_model\n",
            "    model = timm.create_model(\"resnet50_cifar100\", pretrained=True)     # https://huggingface.co/edadaltocg/resnet50_cifar100\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py\", line 138, in create_model\n",
            "    model = create_fn(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/detectors/models/resnet.py\", line 210, in resnet50_cifar100\n",
            "    return _create_resnet_small(\"resnet50_cifar100\", features_dim=2048, pretrained=pretrained, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/detectors/models/resnet.py\", line 135, in _create_resnet_small\n",
            "    torch.hub.load_state_dict_from_url(model.default_cfg.url, map_location=\"cpu\", file_name=f\"{variant}.pth\")\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/hub.py\", line 876, in load_state_dict_from_url\n",
            "    download_url_to_file(url, cached_file, hash_prefix, progress=progress)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/hub.py\", line 717, in download_url_to_file\n",
            "    u = urlopen(req)\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 215, in urlopen\n",
            "    return opener.open(url, data, timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 521, in open\n",
            "    response = meth(req, response)\n",
            "               ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 630, in http_response\n",
            "    response = self.parent.error(\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 553, in error\n",
            "    result = self._call_chain(*args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 492, in _call_chain\n",
            "    result = func(*args)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 745, in http_error_302\n",
            "    return self.parent.open(new, timeout=req.timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 521, in open\n",
            "    response = meth(req, response)\n",
            "               ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 630, in http_response\n",
            "    response = self.parent.error(\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 559, in error\n",
            "    return self._call_chain(*args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 492, in _call_chain\n",
            "    result = func(*args)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 639, in http_error_default\n",
            "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
            "urllib.error.HTTPError: HTTP Error 429: Too Many Requests\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">glamorous-sweep-1</strong> at: <a href='https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/runs/et4y8sbl' target=\"_blank\">https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/runs/et4y8sbl</a><br> View project at: <a href='https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100' target=\"_blank\">https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251204_151546-et4y8sbl/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run et4y8sbl errored: HTTP Error 429: Too Many Requests\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7ym414pw with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006228157055957308\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: SGD\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.00021143341900904775\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'NoisyCIFAR100' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251204_151612-7ym414pw</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/runs/7ym414pw' target=\"_blank\">glowing-sweep-2</a></strong> to <a href='https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/sweeps/8lfbxp0y' target=\"_blank\">https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/sweeps/8lfbxp0y</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100' target=\"_blank\">https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/sweeps/8lfbxp0y' target=\"_blank\">https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/sweeps/8lfbxp0y</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/runs/7ym414pw' target=\"_blank\">https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/runs/7ym414pw</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://huggingface.co/edadaltocg/resnet50_cifar100/resolve/main/pytorch_model.bin\" to /root/.cache/torch/hub/checkpoints/resnet50_cifar100.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/wandb/agents/pyagent.py\", line 297, in _run_job\n",
            "    self._function()\n",
            "  File \"/tmp/ipython-input-941492003.py\", line 94, in sweep_train\n",
            "    model = get_model(config['model']['name'], config).to(device)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3748646692.py\", line 5, in get_model\n",
            "    model = timm.create_model(\"resnet50_cifar100\", pretrained=True)     # https://huggingface.co/edadaltocg/resnet50_cifar100\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py\", line 138, in create_model\n",
            "    model = create_fn(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/detectors/models/resnet.py\", line 210, in resnet50_cifar100\n",
            "    return _create_resnet_small(\"resnet50_cifar100\", features_dim=2048, pretrained=pretrained, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/detectors/models/resnet.py\", line 135, in _create_resnet_small\n",
            "    torch.hub.load_state_dict_from_url(model.default_cfg.url, map_location=\"cpu\", file_name=f\"{variant}.pth\")\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/hub.py\", line 876, in load_state_dict_from_url\n",
            "    download_url_to_file(url, cached_file, hash_prefix, progress=progress)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/hub.py\", line 717, in download_url_to_file\n",
            "    u = urlopen(req)\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 215, in urlopen\n",
            "    return opener.open(url, data, timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 521, in open\n",
            "    response = meth(req, response)\n",
            "               ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 630, in http_response\n",
            "    response = self.parent.error(\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 553, in error\n",
            "    result = self._call_chain(*args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 492, in _call_chain\n",
            "    result = func(*args)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 745, in http_error_302\n",
            "    return self.parent.open(new, timeout=req.timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 521, in open\n",
            "    response = meth(req, response)\n",
            "               ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 630, in http_response\n",
            "    response = self.parent.error(\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 559, in error\n",
            "    return self._call_chain(*args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 492, in _call_chain\n",
            "    result = func(*args)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 639, in http_error_default\n",
            "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
            "urllib.error.HTTPError: HTTP Error 429: Too Many Requests\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">glowing-sweep-2</strong> at: <a href='https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/runs/7ym414pw' target=\"_blank\">https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/runs/7ym414pw</a><br> View project at: <a href='https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100' target=\"_blank\">https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251204_151612-7ym414pw/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 7ym414pw errored: HTTP Error 429: Too Many Requests\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 311lftvj with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.002575775054348585\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: AdamW\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.002810919414539855\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'NoisyCIFAR100' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251204_151617-311lftvj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/runs/311lftvj' target=\"_blank\">peach-sweep-3</a></strong> to <a href='https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/sweeps/8lfbxp0y' target=\"_blank\">https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/sweeps/8lfbxp0y</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100' target=\"_blank\">https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/sweeps/8lfbxp0y' target=\"_blank\">https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/sweeps/8lfbxp0y</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/runs/311lftvj' target=\"_blank\">https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/runs/311lftvj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://huggingface.co/edadaltocg/resnet50_cifar100/resolve/main/pytorch_model.bin\" to /root/.cache/torch/hub/checkpoints/resnet50_cifar100.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/wandb/agents/pyagent.py\", line 297, in _run_job\n",
            "    self._function()\n",
            "  File \"/tmp/ipython-input-941492003.py\", line 94, in sweep_train\n",
            "    model = get_model(config['model']['name'], config).to(device)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-3748646692.py\", line 5, in get_model\n",
            "    model = timm.create_model(\"resnet50_cifar100\", pretrained=True)     # https://huggingface.co/edadaltocg/resnet50_cifar100\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py\", line 138, in create_model\n",
            "    model = create_fn(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/detectors/models/resnet.py\", line 210, in resnet50_cifar100\n",
            "    return _create_resnet_small(\"resnet50_cifar100\", features_dim=2048, pretrained=pretrained, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/detectors/models/resnet.py\", line 135, in _create_resnet_small\n",
            "    torch.hub.load_state_dict_from_url(model.default_cfg.url, map_location=\"cpu\", file_name=f\"{variant}.pth\")\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/hub.py\", line 876, in load_state_dict_from_url\n",
            "    download_url_to_file(url, cached_file, hash_prefix, progress=progress)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/hub.py\", line 717, in download_url_to_file\n",
            "    u = urlopen(req)\n",
            "        ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 215, in urlopen\n",
            "    return opener.open(url, data, timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 521, in open\n",
            "    response = meth(req, response)\n",
            "               ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 630, in http_response\n",
            "    response = self.parent.error(\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 553, in error\n",
            "    result = self._call_chain(*args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 492, in _call_chain\n",
            "    result = func(*args)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 745, in http_error_302\n",
            "    return self.parent.open(new, timeout=req.timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 521, in open\n",
            "    response = meth(req, response)\n",
            "               ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 630, in http_response\n",
            "    response = self.parent.error(\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 559, in error\n",
            "    return self._call_chain(*args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 492, in _call_chain\n",
            "    result = func(*args)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 639, in http_error_default\n",
            "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
            "urllib.error.HTTPError: HTTP Error 429: Too Many Requests\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">peach-sweep-3</strong> at: <a href='https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/runs/311lftvj' target=\"_blank\">https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100/runs/311lftvj</a><br> View project at: <a href='https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100' target=\"_blank\">https://wandb.ai/marius-alexandru-olaru-fii-uaic/NoisyCIFAR100</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251204_151617-311lftvj/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 311lftvj errored: HTTP Error 429: Too Many Requests\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Detected 3 failed runs in the first 60 seconds, killing sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true\n"
          ]
        }
      ]
    }
  ]
}